n-grams are a probabilistic method used in [[Natural Language Processing]] to understand text. They represent contiguous sequences of "n" words or characters that occurs together in a given text.

This method simply counts the occurrences of words on a given dataset and predicts the next word or character, by calculating the probability of the trained table.

n-grams were introduced in the 1990's and were one of the initial methods to provide somwhat accurate suggestions, predictions and classification of text.


# References
https://www.youtube.com/watch?v=PaCmpygFfXo - # The spelled-out intro to language modeling: building makemore. #Andrej_Karpaty

#Bigrams #Trigrams #n-grams